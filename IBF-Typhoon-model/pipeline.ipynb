{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from pybufrkit.decoder import Decoder\n",
    "import json\n",
    "\n",
    "\n",
    "SRC_PATH = Path.cwd() / 'src'\n",
    "if str(SRC_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_PATH))\n",
    "\n",
    "from climada.hazard import Centroids, TropCyclone,TCTracks\n",
    "from climada.hazard.tc_tracks_forecast import TCForecast\n",
    "from typhoonmodel.utility_fun import track_data_clean, Check_for_active_typhoon, Sendemail, ucl_data, plot_intensity, initialize\n",
    "\n",
    "from typhoonmodel.utility_fun import Rainfall_data\n",
    "\n",
    "from typhoonmodel.utility_fun.forecast_process import Forecast\n",
    "\n",
    "decoder = Decoder()\n",
    "from climada.util import coordinates  \n",
    "from typhoonmodel.utility_fun.settings import *\n",
    "print(ecmwf_remote_directory)\n",
    "from typhoonmodel.utility_fun.dynamicDataDb import DatabaseManager\n",
    "\n",
    "from climada.util import coordinates \n",
    "\n",
    "initialize.setup_logger()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folde for storing the data is created if it does not exist\n",
    "\n",
    "# Base forecast directory\n",
    "base_path = Path(\"forecast\")\n",
    "\n",
    "# Define subfolders\n",
    "subfolders = [\n",
    "    base_path / \"Input\" / \"ECMWF\",\n",
    "    base_path / \"Output\",\n",
    "    base_path / \"rainfall\"\n",
    "]\n",
    "\n",
    "# Create all folders if they don't exist\n",
    "for folder in subfolders:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Folder structure created or already exists:\")\n",
    "for folder in subfolders:\n",
    "    print(f\" - {folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize.setup_cartopy()\n",
    "start_time = datetime.now()\n",
    "############## Defult variables which will be updated if a typhoon is active \n",
    "print('---------------------AUTOMATION SCRIPT STARTED---------------------------------')\n",
    "print(str(start_time))\n",
    "\n",
    "for countryCodeISO3 in countryCodes:\n",
    "    logger.info(f\"running piepline for {countryCodeISO3}\")  \n",
    "    admin_level=SETTINGS_SECRET[countryCodeISO3][\"admin_level\"]\n",
    "    mock=SETTINGS_SECRET[countryCodeISO3][\"mock\"]\n",
    "    mock_nontrigger_typhoon_event=SETTINGS_SECRET[countryCodeISO3][\"mock_nontrigger_typhoon_event\"]\n",
    "    mock_trigger_typhoon_event=SETTINGS_SECRET[countryCodeISO3][\"mock_trigger_typhoon_event\"]\n",
    "    mock_trigger=SETTINGS_SECRET[countryCodeISO3][\"if_mock_trigger\"]\n",
    "\n",
    "    # Check if the data folder exists\n",
    "    if not os.path.exists(\"./data\"):\n",
    "        logger.info(\"Data folder not found. Downloading...\")\n",
    "\n",
    "        # Initialize database manager\n",
    "        db = DatabaseManager(countryCodeISO3, admin_level)\n",
    "        filename = 'data.zip'\n",
    "        \n",
    "        # Download the data zip\n",
    "        db.getDataFromDatalake(filename)\n",
    "        logger.info(\"Finished data download and extraction.\")\n",
    "    else:\n",
    "        logger.info(\"Data folder already exists. Skipping download.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "####  check setting for mock data \n",
    "if mock:\n",
    "    if mock_trigger:\n",
    "        typhoon_names=mock_trigger_typhoon_event\n",
    "    else:\n",
    "        typhoon_names=mock_nontrigger_typhoon_event                \n",
    "    logger.info(f\"mock piepline for typhoon{typhoon_names}\")\n",
    "    db = DatabaseManager(countryCodeISO3,admin_level)\n",
    "    json_path = mock_data_path  + typhoon_names             \n",
    "    db.uploadTrackData(json_path)            \n",
    "    db.uploadTyphoonData(json_path)\n",
    "    #db.sendNotificationTyphoon()\n",
    "    db.processEvents()\n",
    "\n",
    "\n",
    "else:\n",
    "    fc = Forecast(countryCodeISO3, admin_level)\n",
    "\n",
    "    if fc.Activetyphoon: #if it is not empty   \n",
    "        for typhoon_names in fc.Activetyphoon:\n",
    "            # upload data\n",
    "            json_path = fc.Output_folder  + typhoon_names  \n",
    "            EAP_TRIGGERED_bool=fc.eap_status_bool[typhoon_names]\n",
    "            EAP_TRIGGERED=fc.eap_status[typhoon_names]                   \n",
    "            fc.db.uploadTrackData(json_path)            \n",
    "            fc.db.uploadTyphoonData(json_path) \n",
    "            fc.db.postResulToDatalake()\n",
    "            fc.db.processEvents()\n",
    "            #fc.db.sendNotificationTyphoon() \n",
    "            \n",
    "\n",
    "    #if there is no active typhoon \n",
    "    else: #\n",
    "        logger.info('no active Typhoon')\n",
    "        df_total_upload=fc.pcode #data frame with pcodes \n",
    "        typhoon_names='null'\n",
    "        df_total_upload['forecast_severity']=0\n",
    "        df_total_upload['forecast_trigger']=0\n",
    "        df_total_upload['affected_population']=0  \n",
    "        df_total_upload['houses_affected']=0      \n",
    "                       \n",
    "        for layer in [\"affected_population\",\"houses_affected\",\"forecast_severity\",\"forecast_trigger\"]:\n",
    "            exposure_entry=[]\n",
    "            # prepare layer\n",
    "            logger.info(f\"preparing data for {layer}\")\n",
    "            exposure_data = {'countryCodeISO3': countryCodeISO3}\n",
    " \n",
    "            exposure_place_codes = []\n",
    "            #### change the data frame here to include impact\n",
    "            for ix, row in df_total_upload.iterrows():\n",
    "                exposure_entry = {\"placeCode\": row[\"adm3_pcode\"],\n",
    "                                    \"amount\": row[layer]}\n",
    "                exposure_place_codes.append(exposure_entry)\n",
    "                \n",
    "            exposure_data[\"exposurePlaceCodes\"] = exposure_place_codes\n",
    "            exposure_data[\"adminLevel\"] = admin_level\n",
    "            exposure_data[\"leadTime\"] = '72-hour'\n",
    "            exposure_data[\"dynamicIndicator\"] = layer\n",
    "            exposure_data[\"disasterType\"] = \"typhoon\"\n",
    "            exposure_data[\"eventName\"] = typhoon_names                     \n",
    "            json_file_path = fc.Output_folder  + typhoon_names+ f'_{layer}' + '.json'\n",
    "            with open(json_file_path, 'w') as fp:\n",
    "                json.dump(exposure_data, fp)\n",
    "            \n",
    "        #upload typhoon data      \n",
    "        json_path = fc.Output_folder\n",
    "        fc.db.uploadTyphoonData_no_event(json_path)  \n",
    "        fc.db.processEvents()\n",
    "                    \n",
    "\n",
    "print('---------------------AUTOMATION SCRIPT FINISHED---------------------------------')\n",
    "print(str(datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tyworkflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
